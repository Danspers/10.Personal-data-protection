# Защита персональных данных

**Описание проекта:**

Необходимо защитить данные клиентов страховой компании «Хоть потоп». Разработать **метод преобразования данных**, чтобы по ним было сложно восстановить **персональную информацию**. Обоснуйте корректность его работы.

Следует учитывать, что при преобразовании данных, качество моделей машинного обучения не ухудшилось. _Подбирать наилучшую модель не требуется_.

**Задача преобразования:** Признаки умножают на обратимую матрицу. Изменится ли качество линейной регрессии?
- **a.** Изменится. Приведите примеры матриц.
- **b.** Не изменится. Указать, как связаны параметры линейной регрессии в исходной задаче и в преобразованной.

## Общий вывод
На практике разница в качестве предсказаний "до" и "после" - не изменится. В процессе вычисления вектора предсказания $a$, матрица $Р$ умножается на свою обратную матрицу $Р^{-1}$, сокращаясь до единичной матрицы $E$  (пошаговое доказательство см. в проекте в разделе _"Умножение матриц"_). Следовательно, кодирование данных с помощью "матричного умножения" не влияет на предсказания модели. Стоит учитывать, что кодирование данных должно происходить до обучения модели.

```
Исходная единичная матрица E (5, 5):
 [[1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]]

Закодированная матрица:
 [[3. 6. 2. 5. 6.]
 [3. 2. 7. 2. 8.]
 [7. 1. 3. 2. 3.]
 [7. 8. 8. 8. 9.]
 [8. 2. 8. 5. 1.]]

Метрика R2 до кодирования признаков:    0.425
Метрика R2 после кодирования признаков: 0.425
```

Алгоритм применим и для другого кол-ва признаков. Для матрицы $P$ можно задать собственную уникальную комбинацию значений, которая станет выполнять роль _ключа_ к кодированию/декодированию данных. Для декодирования матрицы признаков её необходимо умножить на обратную матрицу $P^{-1}$. _Ключ_ можно передавать и использовать между несколькими сотрудниками. 